{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_normalize(X):\n",
    "    #   FEATURENORMALIZE Normalizes the features in X \n",
    "    #   FEATURENORMALIZE(X) returns a normalized version of X where\n",
    "    #   the mean value of each feature is 0 and the standard deviation\n",
    "    #   is 1. This is often a good preprocessing step to do when\n",
    "    #   working with learning algorithms.\n",
    "\n",
    "    # You need to set these values correctly\n",
    "    X_norm = X\n",
    "    mu     = np.zeros(X.shape[1])\n",
    "    sigma  = np.zeros(X.shape[1])\n",
    "    \n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    # Instructions: First, for each feature dimension, compute the mean\n",
    "    #               of the feature and subtract it from the dataset,\n",
    "    #               storing the mean value in mu. Next, compute the \n",
    "    #               standard deviation of each feature and divide\n",
    "    #               each feature by it's standard deviation, storing\n",
    "    #               the standard deviation in sigma. \n",
    "    #\n",
    "    #               Note that X is a matrix where each column is a \n",
    "    #               feature and each row is an example. You need \n",
    "    #               to perform the normalization separately for \n",
    "    #               each feature. \n",
    "    #\n",
    "    # Hint: You might find the 'np.mean' and 'np.std' functions useful.\n",
    "    #  \n",
    "    \n",
    "\n",
    "    mu = np.mean(X, axis=0)\n",
    "    sigma = np.std(X, axis=0)\n",
    "    \n",
    "    X_norm = (X - mu) / sigma\n",
    "    \n",
    "    \n",
    "    # ============================================================\n",
    "    \n",
    "    return X_norm, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_eqn(X, y):\n",
    "    #NORMALEQN Computes the closed-form solution to linear regression \n",
    "    #   NORMALEQN(X,y) computes the closed-form solution to linear \n",
    "    #   regression using the normal equations.\n",
    "\n",
    "    theta = np.zeros(X.shape[1])\n",
    "\n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    # Instructions: Complete the code to compute the closed form solution\n",
    "    #               to linear regression and put the result in theta.\n",
    "    #\n",
    "\n",
    "\n",
    "    theta = np.dot(np.dot(np.linalg.pinv(np.dot(X.T, X)), X.T), y)\n",
    "    # ============================================================\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_training_data(file_name, encoding='big5'):\n",
    "    df = pd.read_csv(file_name, encoding=encoding, na_values=['NR'])\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "df = read_training_data('./train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_training_data(df):\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            df.columns[0]: 'date',\n",
    "            df.columns[1]: 'location',\n",
    "            df.columns[2]: 'feature'\n",
    "    })\n",
    "        \n",
    "    df.date = pd.to_datetime(df.date)\n",
    "    \n",
    "    df = df.drop(columns=['location'])\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = preprocess_training_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = df[df.feature == 'PM2.5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data10 = df[df.feature == 'PM10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_data2 = []\n",
    "for name, group in data2.groupby(data2.date.dt.month):\n",
    "    group = group.drop(columns=['date', 'feature'])\n",
    "    flat_data2.append(group.values.flatten())\n",
    "    \n",
    "flat_data2 = np.array(flat_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_data10 = []\n",
    "for name, group in data10.groupby(data10.date.dt.month):\n",
    "    group = group.drop(columns=['date', 'feature'])\n",
    "    flat_data10.append(group.values.flatten())\n",
    "    \n",
    "flat_data10 = np.array(flat_data10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for m2, m10 in zip(flat_data2, flat_data10):\n",
    "#     print(m.shape)\n",
    "    for i in range(m2.size-9):\n",
    "        X.append(np.append(m2[i:i+9],m10[i:i+9]))\n",
    "        y.append(m2[i+9])\n",
    "X = np.array(X)\n",
    "y = np.array(y).reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_n, mu, sigma = feature_normalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_testing_data(file_name):\n",
    "    df = pd.read_csv(file_name, header=None, na_values=['NR'])\n",
    "    df = df.rename(columns={0: 'id', 1: 'feature'})\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "tdf = read_testing_data('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf2 = tdf[tdf.feature == 'PM2.5']\n",
    "tdf2 = tdf2.drop(columns=['id', 'feature'])\n",
    "t2 = tdf2.values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf10 = tdf[tdf.feature == 'PM10']\n",
    "tdf10 = tdf10.drop(columns=['id', 'feature'])\n",
    "t10 = tdf10.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tdf.index = tdf.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tdf = tdf.drop(columns=['id', 'feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = tdf.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = normal_eqn(np.insert(X_n, 0, 1, 1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = pd.DataFrame(columns=['id', 'value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for y2, y10 in zip(t2, t10):\n",
    "#     print(y2, y10)\n",
    "    t = (np.append(y2, y10)-mu)/sigma\n",
    "    pred.append(np.dot(np.insert(t, 0, 1, 0), theta))\n",
    "\n",
    "pred = np.array(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans.id = tdf.id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans.value = pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans.to_csv('final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_multi(theta, X, y):\n",
    "    m, n = X.shape\n",
    "    h_theta = np.dot(X, theta)\n",
    "    square_error = (h_theta - y)**2\n",
    "    J = 1 / (2 * m) * np.sum(square_error)\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_multi(X, y, theta, alpha, num_iters):\n",
    "    # GRADIENTDESCENT Performs gradient descent to learn theta\n",
    "    # theta = GRADIENTDESCENT(X, y, theta, alpha, num_iters) updates theta by \n",
    "    # taking num_iters gradient steps with learning rate alpha\n",
    "    m, n = X.shape\n",
    "    # Initialize\n",
    "    J_history = np.zeros((num_iters, 1))\n",
    "#     T_history = np.zeros((num_iters,X.shape[1], 1))\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "#         T_history[i] = theta\n",
    "\n",
    "        ### ========= YOUR CODE HERE ============\n",
    "        # Instructions: Perform a single gradient step on the parameter vector theta.\n",
    "        \n",
    "        htheta = np.dot(X, theta)\n",
    "        theta = theta - (alpha / m) * np.dot(X.T, htheta-y)\n",
    "        \n",
    "        ### =====================================\n",
    "        \n",
    "        J_history[i] = compute_cost_multi(theta, X, y)\n",
    "    return theta, J_history#, T_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_theta, J_his = gradient_descent_multi(np.insert(X_n, 0, 1, 1), y, theta, 0.01, 20000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
